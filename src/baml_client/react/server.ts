/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
'use server'

import { b } from '../index';
import type { Check, Checked  } from "../types";
import type { Image, Audio } from "@boundaryml/baml";

import type {  AssistantResponse,  MyUserMessage,  PaymentPlan } from "../types"

import type * as types from "../types"

/**
 * Regular BAML server actions that return direct responses.
 */

/**
 * Executes the "ChatWithLLM" BAML action.
 *
 * This server action calls the underlying BAML function "ChatWithLLM"
 * with the specified parameters.
 *
 * @param { MyUserMessage[] } messages - Input parameter.
 *
 * @returns {Promise<AssistantResponse>} A promise that resolves with the result of the action.
 */
export const ChatWithLLM = async (
  messages: MyUserMessage[],
): Promise<AssistantResponse> => {
  return b.ChatWithLLM(
    messages,
  );
};